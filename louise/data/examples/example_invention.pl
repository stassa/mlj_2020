:-module(path, [background_knowledge/2
	       ,metarules/2
	       ,positive_example/2
	       ,negative_example/2
	       ,edge/2
	       ,not_edge/2
	       ]).

/** <module> Experiment file demonstrating examples invention.

Configuration options
---------------------

The experiments described in this file were carried out with the
following configuration options.

==
?- list_config.
experiment_file(data/drafts/examples_invention/path.pl,path)
learner(louise)
max_invented(0)
recursion_depth_limit(dynamic_learning,200)
recursive_reduction(false)
reduction(plotkins)
resolutions(5000)
theorem_prover(resolution)
true.
==

Examples invention
------------------

The MIL problem defined in the current experiment file can't be solved
because the H22 _Chain_ and _Identity_ metarules are not sufficient to
express a theory entailing the single example path(a,f) given the
background definition of edge/2.

The MIL problem defined in this experiment is as follows:

==
% Single positive example of path/2:
path(a,f).

% Background definition of edge/2
edge(a,b).
edge(b,c).
edge(c,d).
edge(d,e).
edge(e,f).

% Chain and Identity metarules (in Louise's internal representation)
m(identity,P,Q):- m(P,X,Y), m(Q,X,Y).
m(chain,P,Q,R):- m(P,X,Y), m(Q,X,Z), m(R,Z,Y).
==

In particular, the H22 _Chain_, having only two body literals, cannot
represent a path from a to f, which are separated by a distance of five
edges. A first learning attempt therefore fails:

==
?- learn(path/2).
false.
==

With examples invention, atoms of path/2 represenging shorter paths
between nodes are derived from the background definition of edge/2 and
_Chain_ and _Identity_. These shorter paths are short enough that they
can be represented by instances of the H22 _Chain_ and _Identity_.

Adding these invented examples to the set of positive examples allows
Louise to learn a hypothesis general enough to entail not just all
invented examples, but also the initial, path(a,f), example.

The following query and its output demonstrate how examples invention
can be used to solve the MIL problem defined in this experiment file.
Note that the debugging output of the query is listed with spaces added
for improved readability and with sections numbered for later reference:

==
% Learning with invented positive examples.
?- learn_with_examples_invention(path/2, _Ps), print_clauses(_Ps).
% Inventing examples

% Generalised partial examples:          [1]
% m(path,A,B):-m(edge,A,B).
% m(path,A,B):-m(edge,A,C),m(edge,C,B).

% Given and invented examples            [2]
% m(path,a,b).
% m(path,a,c).
% m(path,a,f).
% m(path,b,c).
% m(path,b,d).
% m(path,c,d).
% m(path,c,e).
% m(path,d,e).
% m(path,d,f).
% m(path,e,f).

% Encapsulating problem
% Constructing Top program
% Reducing Top program

% Excapsulating hypothesis               [3]
path(A,B):-edge(A,B).
path(A,B):-edge(A,C),path(C,B).
true.
==

Debugging of learn_with_examples_invention/2 is enabled with the query
debug(examples_invention). This is already added as a directive to the
configuration file so ensure it is uncommented in that file if you want
to replicate the debug output listed below.

In the following sections we further discuss the output of the above
query to learn_with_examples_invention/2.

Generalisation of partial examples
----------------------------------

The first three lines in the debug output of
learn_with_examples_invention/2, above, are generated by
examples_invention/5 (the predicate that performs examples invention):

==
% Generalised partial examples:          [1]
% m(path,A,B):-m(edge,A,B).
% m(path,A,B):-m(edge,A,C),m(edge,C,B).
==

The two clauses listed in [1] are generalisations of the single positive
example, path(a,f) derived from the H22 _Chain_ and _Identity_ and the
background definition of edge/2.

These two clauses in [1] are obtained by Top program construction with
the partially instantiated examples path(a,X) and path(Y,f) added to
the given MIL problem (i.e. the positive and negative examples, BK and
metarules specified in this experiment file). These partial examples are
derived from the given example, path(a,f), by successively replacing
each of its constants with a variable. Replacing the constants in the
path(a,f) example with variables results in atoms of path/2 representing
sub-paths, on the graph represented by edge/2, of the path from "a" to
"f".

The first partial example, path(a,X) represents all paths that can be
reached from the node "a". The second partial example, path(Y,f)
represents all paths that can reach the node "f". Their generalisation
is a set of clauses that suffice to represent all paths from node "a" to
node "f".

Note that, because in this case we have a single example and the
background definition of edge/2 makes for a very simple graph (a
straight path from "a" to "f"), partial examples only represent
sub-paths of path(a,f). In a larger problem, partial examples may also
reprsent paths encompassing path(a,f) as well as paths disjoint to
path(a,f) (e.g. paths starting from node "a" and not crossing the path
from "a" to "f" etc).

Invented examples
-----------------

The next few debug lines list the union of the set of positive
examples, including the one initially given positive example, path(a,f),
and the Least Herbrand Model of the two clauses in [1], i.e. the clauses
derived from the generalisation of the partial examples described in the
previous section:

==
% Given and invented examples            [2]
% m(path,a,b).
% m(path,a,c).
% m(path,b,c).
% m(path,b,d).
% m(path,c,d).
% m(path,c,e).
% m(path,d,e).
% m(path,d,f).
% m(path,e,f).
% m(path,a,f). % Given example
==

The given example, path(a,f) is marked in the debug output block above.
Remaining atoms in the debug output block are invented examples.

The Least Herbrand Model of the two clauses in [1] is generated by
bottom-up evaluation using lfp_query/4 (defined in lib(tp/tp)).

The atoms of path/2 in the LHM of the two clauses in [1] are a set of
paths connecting nodes that can be reached in at most two steps. That is
the maximum number of steps in a path that can be represented by
instances of the H22 _Chain_ and _Identity_ alone.

Note that, while the two clauses generalising partial examples, in [1],
were derived from partial examples representing all paths from node "a"
or to node "f", the invented positive examples in [2] include paths
staring or ending at nodes other than "a" and "f", e.g. path(b,c),
path(d,e), etc. However, each of those sub-paths are paths "on the way"
to node "f" from node "a".

Lerning with invented examples
------------------------------

The entire set of invented examples in [2] includes sub-paths of the
path represented by the single example path(a,f):

==
path(a,b), path(b,c), path(c,d), path(d,e), path(e,f)
==

Each of these sub-paths is short enough to be represented by instances
of the H22 _Chain_ and _Identity_ and the background knowledge
definitions of edge/2. All of those sub-paths taken together suffice to
represent the full path from "a" to "f" using instances of _Chain_ and
_Inverse_.

The result is that with the invented examples in [2] we now have
sufficient examples, background knowledge and metarules to learn a
hypothesis that entails the positive example path(a,f), listed in [3]:

==
% Excapsulating hypothesis               [3]
path(A,B):-edge(A,B).
path(A,B):-edge(A,C),path(C,B).
==

Note that the learned hypothesis does not include the two clauses in
[1], i.e. the generalisations of the partial examples. That is because
the learned hypothesis is learned with only fully-instantiated examples,
the given example, path(a,f) and the invented examples in [2].

Consequently, the learned hypothesis is a hypothesis general enough that
it entails all ground positive examples, invented, or given, but
specific enough that it does not entail the over-general, partial
instantiations of path(a,f) listed in [2].

Irrelevant background knowledge
-------------------------------

The predicates specified as background knowledge for path/2 include a
definition of a predicate not_edge/2:

==
not_edge(1,2).
not_edge(1,3).
not_edge(1,4).
==

not_edge/2 is an irrelevant background predicate- a "decoy", meant to
test the extent to which examples invention results in spurious examples
(i.e. false positives) when given irrelevant background knowledge.

The listing of invented examples in [2] make it clear that no false
positives were invented in this case:

==
% Invented positive examples:
% m(path,a,b).
% m(path,a,c).
% m(path,b,c).
% m(path,b,d).
% m(path,c,d).
% m(path,c,e).
% m(path,d,e).
% m(path,d,f).
% m(path,e,f).
==

For instance, a false positive derived from not_edge/2 might include
path(1,b). Such false positives are excluded by the partial examples.
Partial examples are partially instantiated to the constants in a
true example, so atoms of background knowledge with a domain disjoint to
the domain of the positive examples cannot unify with partial examples,
and will not end up in the set of invented examples.

The situation is different with background knowledge that is irrelevant
but whose domain may partially overlap with the positive examples. For
instance, if we were to redefine not_edge/2 as follows:

==
not_edge(1,b).
not_edge(a,3).
not_edge(a,4).
==

Then the results of example invention would include false positives and
the learned hypothesis would be over-general:

==
?- learn_with_examples_invention(path/2, _Ps), print_clauses(_Ps).
% Inventing examples

% Generalised partial examples:
% m(path,A,B):-m(edge,A,B).
% m(path,A,B):-m(not_edge,A,B).
% m(path,A,B):-m(edge,A,C),m(edge,C,B).

% Given and invented examples
% m(path,1,b).
% m(path,a,3).
% m(path,a,4).
% m(path,a,b).
% m(path,a,c).
% m(path,a,f).
% m(path,b,c).
% m(path,b,d).
% m(path,c,d).
% m(path,c,e).
% m(path,d,e).
% m(path,d,f).
% m(path,e,f).

% Encapsulating problem
% Constructing Top program
% Reducing Top program

% Excapsulating hypothesis
path(A,B):-edge(A,B).
path(A,B):-not_edge(A,B).
path(A,B):-edge(A,C),path(C,B).
true.
==

Let us assume that "not_edge" is sensibly named and represents some
relation of nodes on the graph defined by edge/2 that is not, itself, an
edge. For instance, it might be a reward associated with reaching a
particular node on the graph, etc. Clearly, under this assumption,
not_edge/2 cannot be used to define path/2!

The need to select only relevant background knowledge is a limitation of
examples invention. Some irrelevant backround predicates may result in
false positives and over-generalising hypotheses.

Irrelevant metarules
--------------------

Similar to the effects of irrelevant background predicates, including
irrelevant metarules to a MIL problem may result in example invention of
false positives, and learning of over-generalising hypotheses. Below,
the _Inverse_ and _Switch_ metarules were added to _Chain_ and
_Identity_ before calling learn_with_invented_examples/2:

==
?- learn_with_examples_invention(path/2, _Ps), print_clauses(_Ps).
% Inventing examples

% Generalised partial examples:
% m(path,A,B):-m(edge,A,B).
% m(path,A,B):-m(edge,A,C),m(edge,C,B).
% m(path,A,B):-m(edge,A,C),m(edge,B,C).
% m(path,A,B):-m(edge,A,C),m(path,B,C).

% Given and invented examples
% m(path,a,a).
% m(path,a,b).
% m(path,a,c).
% m(path,a,f).
% m(path,b,a).
% m(path,b,b).
% m(path,b,c).
% m(path,b,d).
% m(path,c,b).
% m(path,c,c).
% m(path,c,d).
% m(path,c,e).
% m(path,d,c).
% m(path,d,d).
% m(path,d,e).
% m(path,d,f).
% m(path,e,a).
% m(path,e,d).
% m(path,e,e).
% m(path,e,f).

% Encapsulating problem
% Constructing Top program
% Reducing Top program

% Excapsulating hypothesis
path(A,B):-edge(A,B).
path(A,B):-edge(B,A).
path(A,B):-edge(A,C),path(C,B).
path(A,B):-edge(A,C),path(B,C).
true.
==

In this case no false positives are actually learned (all of the
invented path/2 atoms are true positive examples of path/2 and still
sub-paths of path(a,f), given that the graph defined by edge/2 is
_undirected_) but the combination of those examples and the new
metarules, _Switch_ and _Inverse_ result in a learned hypothesis that is
overly general, representing paths "doubling back" on themselves and
possibly failing to lead from "a" to "f" altogether.


Examples invention and metarule extension
-----------------------------------------

Attempting to learn a hypothesis of path/2 from the MIL problem defined
in this experiment file using dynamic learning for predicate invention
returns a very specific hypothesis:

==
?- max_invented(I), learn_dynamic(path/2).
'$1'(A,B):-edge(A,C),'$2'(C,B).
'$2'(A,B):-edge(A,C),'$3'(C,B).
'$3'(A,B):-edge(A,C),edge(C,B).
path(A,B):-edge(A,C),'$1'(C,B).
I = 4.
==

As demonstrated in the above experiments, examples invention can, in
some cases, obtain better results than dynamic learning and predicate
invention.

The combination of examples invention and dynamic learning is not yet
fully implemented, and examples invention is not fully integrated to the
main learning predicates, learn/1, learn/2 and learn/5. More
experimenting is needed to understand the interaction of examples
invention and dynamic learning.

For the time being it is not adviced to perform dynamic learning with
invented examples.

*/

% Constraints excluding left-recursive hypotheses.
% These also have the effect of excluding generalisations of partial
% positive examples such as the following:
% path(A,B):-edge(A,C),edge(C,B).
% path(A,B):-path(A,C),path(C,B).
%
configuration:metarule_constraints(M,fail):-
	M =.. [m,_Id,P|Ps]
	,forall(member(P1,Ps)
	       ,P1 == P).

configuration:metarule_constraints(M,fail):-
	M =.. [m,_Id,P|Ps]
	,left_recursive(P,Ps).

left_recursive(T,[T|_Ps]):-
	!.
left_recursive(T,[T,T|_Ps]):-
	!.
left_recursive(T,[I,T|_Ps]):-
	atomic_list_concat([T,A],'_',I)
	,atom_number(A,_N).

% Tells list_learning_results/0 to use the right learning predicate.
configuration:learning_predicate(learn_with_examples_invention/2).

background_knowledge(path/2, [edge/2,not_edge/2]).

metarules(path/2,[chain,identity]).
% Irrelevant metarules added
%metarules(path/2,[chain,identity,inverse,switch]).

positive_example(path/2,path(a,f)).

negative_example(path/2,_):-
	fail.

edge(a,b).
edge(b,c).
edge(c,d).
edge(d,e).
edge(e,f).


%/* Irrelevant BK
not_edge(1,2).
not_edge(1,3).
not_edge(1,4).
%*/

/* Partially relevant BK
not_edge(1,b).
not_edge(a,3).
not_edge(a,4).
*/

/*
Target theory:

path(X,Y):-
	edge(X,Y).
path(X,Y):-
	edge(X,Z)
	,path(Z,Y).
*/
